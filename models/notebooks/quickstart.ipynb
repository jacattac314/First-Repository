{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML/AI Models Quick Start\n",
    "\n",
    "This notebook demonstrates the cost prediction and anomaly detection models for AI agent operations.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from src.cost_prediction_model import CostPredictionModel, LLMProvider, AgentExecutionFeatures\n",
    "from src.anomaly_detection_model import AnomalyDetectionModel, ExecutionMetrics\n",
    "from src.training_utils import SyntheticDataGenerator, ModelEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cost Prediction Model\n",
    "\n",
    "Predict costs before running AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "cost_model = CostPredictionModel()\n",
    "\n",
    "# Define agent execution features\n",
    "features = AgentExecutionFeatures(\n",
    "    agent_type='data_analyzer',\n",
    "    task_complexity=7,\n",
    "    data_scope_size=1000,\n",
    "    has_tool_use=True,\n",
    "    max_iterations=3,\n",
    "    provider=LLMProvider.CLAUDE_SONNET,\n",
    "    historical_avg_tokens=5200\n",
    ")\n",
    "\n",
    "# Predict cost\n",
    "prediction = cost_model.predict_cost(features)\n",
    "\n",
    "print(f\"Predicted Cost: ${prediction['predicted_cost_usd']:.4f}\")\n",
    "print(f\"Predicted Tokens: {prediction['predicted_tokens']:,}\")\n",
    "print(f\"Confidence: {prediction['confidence']:.1%}\")\n",
    "print(f\"\\nRecommendation: {prediction['recommendation']}\")\n",
    "print(\"\\nAlternative Providers:\")\n",
    "for alt in prediction['cost_alternatives'][:3]:\n",
    "    print(f\"  {alt['provider']}: ${alt['estimated_cost_usd']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Anomaly Detection Model\n",
    "\n",
    "Detect unusual patterns in agent executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic training data\n",
    "generator = SyntheticDataGenerator(seed=42)\n",
    "training_data = generator.generate_agent_executions(\n",
    "    n_agents=5,\n",
    "    executions_per_agent=100,\n",
    "    include_anomalies=True,\n",
    "    anomaly_rate=0.05\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(training_data)} training executions\")\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train anomaly detector\n",
    "detector = AnomalyDetectionModel(sensitivity=3.0)\n",
    "detector.train(training_data)\n",
    "\n",
    "print(\"Anomaly detector trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with normal execution\n",
    "normal_execution = ExecutionMetrics(\n",
    "    agent_id='agent_000',\n",
    "    execution_id='exec_test_1',\n",
    "    timestamp=datetime.now(),\n",
    "    duration_seconds=15.2,\n",
    "    total_tokens=5100,\n",
    "    cost_usd=0.082,\n",
    "    success=True,\n",
    "    error_type=None,\n",
    "    api_calls_made=8,\n",
    "    provider='claude-sonnet'\n",
    ")\n",
    "\n",
    "result = detector.detect(normal_execution)\n",
    "print(\"Normal Execution:\")\n",
    "print(f\"  Is Anomaly: {result.is_anomaly}\")\n",
    "print(f\"  {result.explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with anomalous execution (cost spike)\n",
    "anomaly_execution = ExecutionMetrics(\n",
    "    agent_id='agent_000',\n",
    "    execution_id='exec_test_2',\n",
    "    timestamp=datetime.now(),\n",
    "    duration_seconds=55.0,\n",
    "    total_tokens=25000,\n",
    "    cost_usd=0.45,\n",
    "    success=True,\n",
    "    error_type=None,\n",
    "    api_calls_made=35,\n",
    "    provider='claude-sonnet'\n",
    ")\n",
    "\n",
    "result = detector.detect(anomaly_execution)\n",
    "print(\"Anomalous Execution:\")\n",
    "print(f\"  Is Anomaly: {result.is_anomaly}\")\n",
    "print(f\"  Type: {result.anomaly_type.value if result.anomaly_type else 'N/A'}\")\n",
    "print(f\"  Severity: {result.severity.value if result.severity else 'N/A'}\")\n",
    "print(f\"  Confidence: {result.confidence:.1%}\")\n",
    "print(f\"  {result.explanation}\")\n",
    "print(f\"  Action: {result.recommended_action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Batch Predictions\n",
    "\n",
    "Analyze multiple executions at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test executions\n",
    "test_data = generator.generate_agent_executions(\n",
    "    n_agents=3,\n",
    "    executions_per_agent=50,\n",
    "    include_anomalies=True,\n",
    "    anomaly_rate=0.1\n",
    ")\n",
    "\n",
    "# Convert to ExecutionMetrics\n",
    "test_executions = [\n",
    "    ExecutionMetrics(\n",
    "        agent_id=row['agent_id'],\n",
    "        execution_id=row['execution_id'],\n",
    "        timestamp=row['timestamp'],\n",
    "        duration_seconds=row['duration_seconds'],\n",
    "        total_tokens=row['total_tokens'],\n",
    "        cost_usd=row['cost_usd'],\n",
    "        success=row['success'],\n",
    "        error_type=row['error_type'],\n",
    "        api_calls_made=row['api_calls_made'],\n",
    "        provider=row['provider']\n",
    "    )\n",
    "    for _, row in test_data.iterrows()\n",
    "]\n",
    "\n",
    "# Batch detect anomalies\n",
    "anomaly_results = detector.batch_detect(test_executions)\n",
    "\n",
    "# Show anomalies only\n",
    "anomalies = anomaly_results[anomaly_results['is_anomaly'] == True]\n",
    "print(f\"\\nDetected {len(anomalies)} anomalies out of {len(test_executions)} executions\")\n",
    "anomalies[['agent_id', 'anomaly_type', 'severity', 'confidence', 'explanation']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cost Optimization Analysis\n",
    "\n",
    "Compare costs across different providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare providers for the same task\n",
    "providers = [\n",
    "    LLMProvider.CLAUDE_HAIKU,\n",
    "    LLMProvider.CLAUDE_SONNET,\n",
    "    LLMProvider.CLAUDE_OPUS,\n",
    "    LLMProvider.GPT35,\n",
    "    LLMProvider.GPT4\n",
    "]\n",
    "\n",
    "results = []\n",
    "for provider in providers:\n",
    "    features = AgentExecutionFeatures(\n",
    "        agent_type='customer_support',\n",
    "        task_complexity=5,\n",
    "        data_scope_size=100,\n",
    "        has_tool_use=False,\n",
    "        max_iterations=1,\n",
    "        provider=provider,\n",
    "        historical_avg_tokens=2000\n",
    "    )\n",
    "    pred = cost_model.predict_cost(features)\n",
    "    results.append({\n",
    "        'provider': provider.value,\n",
    "        'cost': pred['predicted_cost_usd'],\n",
    "        'tokens': pred['predicted_tokens']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(results).sort_values('cost')\n",
    "print(\"\\nProvider Cost Comparison (for customer support task):\")\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Models and Data\n",
    "\n",
    "Export for production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training data\n",
    "generator.save_dataset(training_data, '../data/training_data.csv')\n",
    "\n",
    "print(\"Models and data ready for production integration!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
